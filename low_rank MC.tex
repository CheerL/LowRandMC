\documentclass[UTF8]{ctexart}
%\documentclass{article}

%---------------------------标题设置----------------------------

	\title{低秩矩阵完整化问题的几种高效解法}
	\author{林陈冉}
	\date{\today}

%---------------------------宏包加载----------------------------
	\usepackage{amsmath}
	\usepackage{amssymb}
	\usepackage{amsthm}
	\usepackage{geometry}
		\geometry{left = 2.54cm, right = 2.54cm, top = 3.18cm, bottom = 3.18cm}
	\usepackage{fancyhdr}
		\pagestyle{fancy}
		%\lfoot{\today}
		\cfoot{\thepage}
		%\rfoot{林陈冉}
		\setlength{\parskip}{0.5 \baselineskip}

%---------------------------定理环境----------------------------
	\newtheorem{theo}{\bf 定理}[section]
	\newtheorem{define}{\bf 定义}[section]
	\newtheorem{algo}{\bf 算法}
	\renewcommand{\proofname}{\bf 证明}
	\renewcommand{\theequation}{\thesection.\arabic{equation}}
	%\numberwithin{equation}{section}

\begin{document}
\maketitle
	\section{简介}
		\subsection{什么是低秩矩阵完整化(low-rank matrix completion)}
			\paragraph{}
				\quad 简单来说, 低秩矩阵完整化问题, 就是在仅仅知道矩阵的少部分元素的情况下, 恢复出这个矩阵的所有元素. 这个问题在统计, 图像处理, 计算几何, 机器学习, 信号处理, 模型控制等方面有广泛应用, 比如著名的NetFlix大奖赛问题.

		\subsection{数学模型}
			\paragraph{}
				\quad 显而易见, 补全一个完全随机的矩阵几乎是不可能的, 也是意义不大的. 一般情况下, 我们认为所需要补全的矩阵是有一定规律的, 也就是说, 这个矩阵的秩比较小. 通常我们最感兴趣的是这样的一个最优化问题:
				\begin{equation}
					\begin{split}\label{q1}
						\min \quad
							& rank(X)\\
						\text{s.t.} \quad
							& X_{ij}=M_{ij},\forall(i,j)\in\Omega\\
					\end{split}
				\end{equation}
				其中 $X, M\in\mathbb{R}^{p\times q}$ , $\Omega$ 是已知元素的下标 $(i, j)$ 构成的集合, $\lvert{\Omega}\rvert = m$ .

			\paragraph{}
				\quad 在一些情况下, (\ref{q1})等价于线性约束问题:
				\begin{equation}
					\begin{split}\label{q2}
						\min \quad
							& rank(X)\\
						\text{s.t.} \quad
							& \mathcal{A}(X)=b\\
					\end{split}
				\end{equation}
				其中$b = (b_1, \cdots, b_m)\in\mathbb{R}^{m}$ ,
				$\mathcal{A}: \mathbb{R}^{p \times q} \rightarrow \mathbb{R}^{m}$ 是线性算子,
				$\mathcal{A}(X) = (\langle{A_1, X}\rangle, \cdots, \langle{A_m, X}\rangle)$ ,
				$A_i \in \mathbb{R}^{p \times q}, \forall i = 1, \cdots, m$ ,
				$\langle{A, X}\rangle$ 是矩阵内积,

			\paragraph{}
				\quad 在此给出线性算子 $\mathcal{A}$ 的共轭算子的定义:
				$\mathcal{A}^*: \mathbb{R}^{m} \rightarrow \mathbb{R}^{p \times q}$ ,
				$\mathcal{A}^*(y) = \sum^m_{i = 1}y_i A_i, \forall y = (y_1, \cdots, y_m) \in \mathbb{R}^{m}$ .
				容易验证 $\mathcal{A}$ 和 $\mathcal{A}^*$ 是well-defined, 即
				\[
						\langle{\mathcal{A}(X), y}\rangle 
					=	\langle{(\langle{A_i, X}\rangle), (y_i)}\rangle
					=	\sum^m_{i = 1}y_i \langle{A_i, X}\rangle
					=	\langle{\sum^m_{i = 1}y_i A_i, X}\rangle
					=	\langle{\mathcal{A}^*(y), X}\rangle
					=	\langle{X, \mathcal{A}^*(y)}\rangle
				\]

			\paragraph{}
				\quad 但是(\ref{q1}), (\ref{q2})都是\textbf{"NP-难"}的, 因此需要一定的转化. 这里我们用核范数来近似矩阵的秩, 把(\ref{q1})与(\ref{q2})转化为以下形式:
				\begin{equation}
					\begin{split}\label{q3}
						\min \quad
							& \lVert{X}\rVert_*\\
						\text{s.t.} \quad
							& \mathcal{A}(X)=b\\	
					\end{split}
				\end{equation}
				\begin{equation}
					\begin{split}\label{q4}
						\min \quad
							& \lVert{X}\rVert_*\\
						\text{s.t.} \quad
							& X_{ij}=M_{ij},\forall(i,j)\in\Omega\\
					\end{split}
				\end{equation}

			\paragraph{}
				\quad 很自然的, 一个重要的问题是: (\ref{q1})与(\ref{q3}), 或者(\ref{q2})与(\ref{q4})什么时候等价? 略过证明, 直接描述以下重要的结论:

			\paragraph{}
				\quad 对于(\ref{q3}), Candes和陶哲轩等给出了一个证明. 当在某些条件下, 若已知元素个数 $\lvert{\Omega}\rvert = m = O(nr \cdot polylog(n))$ , 其中 $n=max(p,q)$ , $polylog$ 是多重对数函数, 则矩阵有很高概率可以通过(\ref{q3})恢复.

			\paragraph{}
				\quad 对于(\ref{q4}), Recht等给出了一个证明. 将线性映射 $\mathcal{A}$ 的矩阵形式记作 $A$ , 即 $\mathcal{A}(X) = A\text{vec}(X)$ , 其中 $\text{vec}(X) \in \mathbb{R}^{pq}$ 为矩阵 $X$ 的向量化. 当 $A$ 是一个随机高斯矩阵, 若向量 $b$ 的维数 $m \ge C(r(p + q)log(pq)$ , 其中 $C$ 是一个正的常数, 则矩阵有很高概率可以通过(\ref{q4})恢复.

			\paragraph{}
				\quad 实际上, 由线性代数知识容易知道, (\ref{q4})要求的线性约束条件并不总能成立, 因此有时需要适当松弛. 考虑(\ref{q4})的罚函数:
				\begin{equation}\label{q5}
					\min \quad \lVert{X}\rVert_*+ \frac{1}{2\mu} \lVert{\mathcal{A}(X) - b}\rVert_2^2
				\end{equation}
				其中 $\mu$ 是某个给定常数.

			\paragraph{}
				\quad 下面, 将对(\ref{q3}), (\ref{q4}), (\ref{q5})分别给出一种高效的解法.

	\section{交替方向增广Lagrange法}
		\subsection{问题转化}
			\paragraph{}
				\quad 对于问题(\ref{q3}), 我们考虑它的对偶问题
				\begin{equation}
					\begin{split}\label{dual1}
						\max_{y \in \mathbb{R}^{m}} \quad
							& b^\top y\\
						\text{s.t.} \quad
							& \lVert{\mathcal{A}^*(y)}\rVert_2 \le 1\\
					\end{split}
				\end{equation}

			\paragraph{}
				\quad 引入一个形式上的变量 $S$ , 将(\ref{dual1})变为如下的等价形式
				\begin{equation}
					\begin{split}\label{dual2}
						\min_{y \in \mathbb{R}^{m}}
							& -b^\top y\\
						\text{s.t.} \quad
							& \mathcal{A}^*(y) - S = 0\\
							& {\lVert{S}\rVert}_2 \le 1\\
					\end{split}
				\end{equation}

			\paragraph{}
				\quad 可以考虑(\ref{dual2})的增广Lagrange函数
				\begin{equation}\label{Lag}
						L(y, S, X, \mu)
					=	-b^\top y + \langle{X, \mathcal{A}^*(y) - S}\rangle + \frac{1}{2\mu} \lVert{\mathcal{A}^*(y) - S}\rVert^2_F
				\end{equation}
				其中 $X \in \mathbb{R}^{p \times q}$ 是某个给定的矩阵(不同于原问题中的 $X$ ), ${\lVert{\cdot}\rVert}_F$ 是矩阵的 $F-$范数.

			\paragraph{}
				\quad 由此我们得到(\ref{dual1})的一个等价问题
				\begin{equation}
					\begin{split}\label{dualQ}
						\min_{y,S} \quad
							& L(y, S, X, \mu)\\
						\text{s.t.} \quad
							& {\lVert{S}\rVert}_2 \le 1\\
					\end{split}
				\end{equation}
				通过选取最佳的 $\mu$ 和 $X$ 可以求出(\ref{dualQ})的最优解.
		
		
			\paragraph{}
				\quad 采用如下的迭代过程以求解问题(\ref{dualQ})
				\begin{equation}
					\begin{split}\label{dualA}
							\mu^{k + 1}
						\in	& [\alpha \mu^k, \mu^k], \quad \alpha \in (0,1)\\
							X^{k + 1}
						=	& X^k + \frac{\mathcal{A}^*(y^{k + 1}) - S^{k + 1}}{\mu^k}\\
							(y^{k + 1}, S^{k + 1}) 
						=	& \arg \min_{y, S}L(y, S, X^k, \mu^k)
					\end{split}
				\end{equation}
		\subsection{交替方向求解}
			\paragraph{}
				\quad 但实际上, (\ref{dualA})并不容易解, 因此我们考虑使用交替方向法来求解这个方程, 即
				\begin{align}
						y^{k + 1}
					=	& \arg \min_{y, S}L(y, S^k, X^k, \mu^k) \label{FixS}\\
						S^{k + 1}
					=	& \arg \min_{y, S}L(y^{k + 1}, S, X^k, \mu^k) \label{FixY}
				\end{align}
				$\mu^{k + 1}$ 和 $X^{k + 1}$ 的求法不变.

			\paragraph{}
				\quad 首先来求解(\ref{FixS}), 当固定 $S^k$
				\begin{equation}\label{LagFixS}
						L(y, S^k, X^k, \mu^k)
					=	-b^\top y + \mathcal{A}(X^k)^\top y - \langle{X, S^k}\rangle+ \frac{1}{2\mu^k} \lVert{\mathcal{A}^*(y) - S^k}\rVert^2_F
				\end{equation}

				记 $T = \mathcal{A}^*(y) - S^k$ , $\mathcal{A}_{ij} = (A_{1_{ij}}, \cdots, A_{m_{ij}}) \in \mathbb{R}^{m}$ ,考虑 $\lVert{T}\rVert^2_F$
				\[
						\lVert{T}\rVert^2_F
					=	\sum_{i, j}((\sum^m_{k = 1} y_k A_{k_{ij}}) - S^k_{ij})^2
					=	\sum_{i, j}(\mathcal{A}_{ij}^\top y - S^k_{ij})^2
				\]
				则它对y的梯度
				\begin{equation}
					\begin{aligned}
							& \frac{\partial \lVert{T}\rVert^2_F}{\partial y}\\
						=	& \frac{\partial \sum_{i, j}(\mathcal{A}_{ij}^\top y - S^k_{ij})^2}{\partial y}\\
						=	& \sum_{i, j}\frac{\partial (\mathcal{A}_{ij}^\top y - S^k_{ij})^2}{\partial y} \\
						=	& 2\sum_{i, j}(\mathcal{A}_{ij}^\top y - S^k_{ij}) \mathcal{A}_{ij}\\
						=	& 2(\sum_{i, j}T_{ij} A_{k_{ij}})\\
						=	& 2(\langle{A_i, T}\rangle)\\
						=	& 2\mathcal{A}(\mathcal{A}^*(y) - S^k)
					\end{aligned}
				\end{equation}

			\paragraph{}
				\quad 由此可以给出(\ref{LagFixS})的梯度
				\begin{equation}\label{GradFixS}
						\frac{\partial L(y, S^k, X^k, \mu^k)}{\partial y}
					=	-b + \mathcal{A}(X^k) + \frac{1}{\mu^k} \mathcal{A}(\mathcal{A}^*(y) - S^k)
				\end{equation}

			\paragraph{}
				\quad 令(\ref{GradFixS})式等于0, 可得
				\begin{equation}\label{dualAY}
					y^{k + 1} = \mu^k(b - \mathcal{A}(X^k)) + \mathcal{A}(S^k)
				\end{equation}

			\paragraph{}
				\quad 再考虑(\ref{FixY}). 当固定 $y^k$
				\begin{equation}
					\begin{split}\label{LagFixY}
							& L(y^{k + 1},S,X^k,\mu^k)\\
						=	& -b^\top y^{k + 1} + \mathcal{A}(X^k)^\top y^{k + 1} - \langle{X, S}\rangle + \frac{1}{2\mu^k} \lVert{\mathcal{A}^*(y^{k + 1}\rVert) - S}^2_F\\
						=	& \frac{1}{2\mu^k}(\lVert{S}\rVert_F^2 - 2\langle{Y, S}\rangle + \lVert{\mathcal{A}^*(y^{k + 1}\rVert)}_F^2) - b^\top y^{k + 1} + \mathcal{A}(X^k)^\top y^{k + 1}\\
					\end{split}
				\end{equation}
				其中 $Y = \mathcal{A}^*(y^{k + 1}) + \mu^k X^k$.
				\begin{equation}\label{GradFixY}
						\frac{\partial L(y^{k + 1},S,X^k,\mu^k)}{\partial S}
					=	\frac{1}{2\mu^k}(\frac{\partial \lVert{S}\rVert_F^2}{\partial S} - 2 \frac{\partial \langle{Y, S}\rangle}{\partial S})
					=	\frac{S - Y}{\mu^k}
				\end{equation}

			\paragraph{}
				\quad 令(\ref{GradFixY})式等于0, 则可得 $S^{k + 1} = Y$ , 但由约束条件 $\lVert{S}\rVert_2 \leq 1$ , 需对 $Y$ 进行修正, 即
				\begin{equation}\label{dualAS}
					S^{k + 1} = U \text{Diag}(\min \{\sigma, 1\}) V^\top
				\end{equation}
				其中 $Y = U \text{Diag}(\sigma) V^\top$ . 根据 $Y$ 的定义, 可以简化 $X^{k + 1}$ 的计算方法
				\begin{equation}\label{dualAX}
						X^{k + 1}
					=	\frac{\mu^kX^k + \mathcal{A}^*(y^{k + 1})-S^{k + 1}}{\mu^k}
					=	\frac{Y - S^{k + 1}}{\mu^k}
				\end{equation}

			\paragraph{}
				\quad 重复进行上述迭代,到目标精度停止,下面给出相应算法
				\begin{algo}
					\quad\\
					步1 \quad 给出 $\mu^0$ , $X^0$ , $y^0$ , $S^0$ , $\epsilon$ , $\alpha$ , 设置计数器 $k=0$ ;\\
					步2 \quad 若 $\frac{\lVert{X^{k + 1} - X^k}\rVert_F}{\max \{1, \lVert{X^k}\rVert_F\}} \leq \epsilon$ , 则停止;\\
					步3 \quad 计算 $y^{k + 1} = \mu^k (b - \mathcal{A}(X^k)) + \mathcal{A}(S^k)$ ;\\
					步4 \quad 计算 $Y = \mathcal{A}^*(y^{k + 1}) + \mu^k X^k$ , 并计算其SVD: $Y = U \text{Diag}(\sigma) V^\top$ ;\\
					步5 \quad 计算 $S^{k + 1} = U \text{Diag}(min \{\sigma, 1\}) V^\top$ ;\\
					步6 \quad 计算 $X^{k + 1} = \frac{Y - S^{k + 1}}{\mu^k}$ ;\\
					步7 \quad 计算 $\mu^{k + 1} = \alpha \mu^k$ , $k = k + 1$,转步2.
				\end{algo}

	\section{RBR法}
		\subsection{SDP问题与Schur补}
			\paragraph{}
				\quad 对于问题(\ref{q4}), 我们可以考虑把它转化为一个半定规划(SDP)问题.

			\paragraph{}
				\quad 一个标准的半定规划问题是
				\begin{equation}
					\begin{split}\label{SDP}
						\min_{X \in S^n} \quad
							& \langle{C, X}\rangle\\
						\text{s.t.} \quad
							& \mathcal{A}(X) = b, X \succ 0
					\end{split}
				\end{equation}
				其中 $b \in \mathbb{R}^{m}$ , $\mathcal{A}(X) = (\langle{A_1, X}\rangle, \cdots, \langle{A_m, X}\rangle)$ , $C, A_i \in S^n$ , $S^n$ 是全体对称矩阵.

			\paragraph{}
				\quad 对于一个对称正定矩阵 $X \in S^n$ , 我们可以把它写成分块矩阵的形式
				\begin{equation}
						X
					=	\begin{pmatrix}
							\xi & y^\top \\
							y & B
						\end{pmatrix}
				\end{equation}
				其中$\xi \in \mathbb{R}^{}$ , $y \in \mathbb{R}^{n-1}$ , $B \in S^{n - 1}$ .

			\paragraph{}
				\quad 容易验证的, $X$ 可以表示为以下形式
				\begin{equation}\label{Schur}
						X 
					=	\begin{pmatrix}
							1 & y^\top B^{-1} \\
							0 & I
						\end{pmatrix}
						\begin{pmatrix}
							\xi - y^\top B^{-1} y & 0 \\
							0 & B
						\end{pmatrix}
						\begin{pmatrix}
							1 & 0 \\
							B^{-1} y & I
						\end{pmatrix}
				\end{equation}
				记 $(X/B) = \xi - y^\top B^{-1} y$ , 称为X对于B的Schur补.

			\paragraph{}
				\quad 显然的
				\begin{equation}\label{SchurCondition}
					X \succeq 0 \Leftrightarrow B \succeq 0, (X/B) \geq 0
				\end{equation}

		\subsection{SOCP问题}
			\paragraph{}
				\quad 约定以下记号
				\begin{equation}
						X_{\alpha, \beta}
					=
					\begin{cases}
						x_{\alpha \beta}
							&\alpha, \beta \in \mathbb{R}^{}\\
						(x_{\alpha \beta_1}, \cdots, x_{\alpha \beta_n})
							&\alpha \in \mathbb{R}^{}, \beta = \{\beta_1, \cdots, \beta_n\}\\
						(x_{\alpha_1 \beta}, \cdots, x_{\alpha_m \beta})^\top
							&\alpha = \{\alpha_1, \cdots, \alpha_m\}, \beta \in \mathbb{R}^{}\\
						\begin{pmatrix}
							x_{\alpha_1 \beta_1} & \cdots & x_{\alpha_1 \beta_n} \\
							\cdots & \cdots & \cdots\\
							x_{\alpha_m \beta_1} & \cdots & x_{\alpha_m \beta_n}
						\end{pmatrix}
							&\alpha = \{\alpha_1, \cdots, \alpha_m\}, \beta = \{\beta_1, \cdots, \beta_n\}
					\end{cases}
				\end{equation}
				\begin{equation}
						i^c
					=	\{1, \cdots, n\} \backslash \{i\}
					=	\{1, \cdots, i-1, i+1, \cdots, n\}
				\end{equation}

			\paragraph{}
				\quad 令
				$
						X
					=	\begin{pmatrix}
							\xi & y^\top \\
							y & B
						\end{pmatrix}
					=	\begin{pmatrix}
							X_{i, i} & X_{i, i^c} \\
							X_{i^c, i} & X_{i^c, i^c}
						\end{pmatrix}
				$,
				等号在相差一个初等变化下成立. 基于(\ref{SchurCondition}), 令 $i$ 取遍 $\{1, \cdots, n\}$ , 逐行解如下的SOCP问题来解决SDP问题(\ref{SDP})

				\begin{equation}
					\begin{split}\label{SOCP}
						\min_{[\xi; y] \in \mathbb{R}^{n}} \quad
							& \bar{c}^\top \begin{pmatrix}\xi \\ y\end{pmatrix}\\
						\text{s.t.} \quad
							& \bar{X} \begin{pmatrix}\xi \\ y\end{pmatrix} = \bar{b}\\
							& (X/B) \geq \delta
					\end{split}
				\end{equation}

				其中
				\begin{equation}
					\begin{split}\label{SOCPCondition}
							\bar{c}
						=	\begin{pmatrix} C_{i, i} \\ 2C{i^c, i} \end{pmatrix} , \quad
							\bar{X}
						=	\begin{pmatrix}
								X^(1)_{i, i} & 2X^(1)_{i, i^c} \\
								\cdots & \cdots \\
								X^(m)_{i, i} & X^(m)_{i, i^c}
							\end{pmatrix} , \quad
							\bar{b}
						=	\begin{pmatrix}
								b_1 - \langle{X^(1)_{i^c, i^c}, B}\rangle \\
								\cdots \\
								b_m - \langle{X^(m)_{i^c, i^c}, B}\rangle 
							\end{pmatrix}
					\end{split}
				\end{equation}
				
				若 $X$ 是半正定的, 即 $X \succeq 0$ , 取 $\delta = 0$; 
				
				若 $X$ 是正定的, 即 $X \succ 0$ , 用大于零的数来限制Schur补, 取$\delta > 0$.

		\subsection{Powell罚函数}
			\paragraph{}
				\quad 考虑(3.7)的Powell罚函数
				\begin{equation}\label{Powell}
						F(X, \theta, \mu)
					=	\bar{c}^\top \begin{pmatrix}\xi \\ y\end{pmatrix} + \frac{1}{2\mu} \lVert{\bar{X}[\xi; y] - \bar{b}- \theta}\rVert^2_2
				\end{equation}
				其中 $\theta \in \mathbb{R}^{m}$ , $\mu > 0$ 都是是给定的. 记 $\lambda = \theta + \bar{b}$

			\paragraph{}
				\quad (\ref{SOCP})等价于以下问题
				\begin{equation}
					\begin{split}\label{PowellQ}
						\min_{X} \quad
							& F(X, \lambda, \mu) = \bar{c}^\top \begin{pmatrix}\xi \\ y\end{pmatrix} + \frac{1}{2\mu} \lVert{\bar{X}[\xi; y] - \lambda}\rVert^2_2\\
						\text{s.t.} \quad
							& X \succeq 0
					\end{split}
				\end{equation}

		\subsection{用SDP和RBR法补全矩阵}
			\paragraph{}
				\quad 回头考虑(\ref{q4}). 当 $X \in S^n$ 对称正定, 有 $\lVert{X}\rVert_* = tr(X)$, (\ref{q4})等价于下面的SDP问题
				\begin{equation}
					\begin{split}\label{RBR}
						\min_X \quad
							& tr(X) = \langle{E, X}\rangle\\
						\text{s.t.} \quad
							& X_{ij} = M_{ij}, \quad \forall(i, j) \in \Omega
					\end{split}
				\end{equation}

			\paragraph{}
				\quad 当 $X \in \mathbb{R}^{p \times q}$ 不是对称正定的, 可以考虑一个更大的对称正定矩阵 $W$ . 当补全了 $W$ , 则 $X$ 自然被补全了(当然, 当 $X$ 是对称正定矩阵时, 我们也可以这么做)
				\begin{equation}
					\begin{split}\label{BigRBR}
						\min_X \quad
							& tr(X)\\
						\text{s.t.} \quad
							& X =	\begin{pmatrix}
										X_1 & W \\
										W^\top & X_2
									\end{pmatrix} \succ 0\\
							& W_{ij} = M_{ij}, \quad \forall(i, j) \in \Omega
					\end{split}
				\end{equation}
				其中 $X \in S^{n}$ , $n = p + q$ ,$W_1 \in S^p$ , $W_2 \in  S^q$ , $X, W_1, W_2 \succ \delta$.

			\paragraph{}
				\quad 我们主要讨论一般的情况, 即问题(\ref{BigRBR}). 采用RBR法, 对于某个 $i$ , 我们把向量 $y$ 分为两个部分, 即
				\begin{equation}\label{BigRBRCondition1}
					y = \begin{pmatrix}y_1 \\ y_2\end{pmatrix}, \quad
					y_1 = X_{\alpha_i, i}, \quad
					y_2 = X_{\beta_i, i}
				\end{equation}
				其中
				$
					\alpha_i=
						\begin{cases}
							\{j + p \vert (i, j \in \Omega)\}, i \leq p\\
							\{j \vert (j, i - p) \in \Omega\}, p < i \leq n
						\end{cases}
						,\quad
					\beta_i = 
						\{1, \cdots, p\} \backslash (\alpha_i \cup \{i\})
				$,
				$y_1$ 是 $X$ 第 $i$ 列除去第 $i$ 行后所有已知元素构成的列向量,$y_2$ 是 $X$ 第 $i$ 列除去第 $i$ 行后所有未知元素构成的列向量.

			\paragraph{}
				\quad 相应的,
				$
						B 
					=	\begin{pmatrix}
							X_{\alpha_i, \alpha_i} & X_{\alpha_i, \beta_i} \\
							X_{\beta_i, \alpha_i} & X_{\beta_i, \beta_i}
						\end{pmatrix} ,\quad 
						\xi
					=	X_{i, i}
				$.
				同时,可以给出 $\bar{X} \begin{pmatrix}\xi \\ y\end{pmatrix}, \lambda$ 和 $\bar{c}$ 的显式表达
				\begin{equation}\label{BigRBRCondition2}
						\lambda
					= 	\begin{cases}
							(M_{i,\alpha_i-p})^\top,&i\leq p\\
							M_{\alpha_i,i-p}\;,&p<i\leq n
						\end{cases}
						, \quad
						\bar{X} \begin{pmatrix} \xi \\ y \end{pmatrix}
					=	y_1
						, \quad
						\bar{c}
					=	(1, \overbrace{0, \cdots, 0}^{n - 1})
				\end{equation}

			\paragraph{}
				\quad 故(\ref{PowellQ})化为以下形式
				\begin{equation}
					\begin{split}\label{TrueRBRQ}
						\min \quad
							& \xi + \frac{1}{2\mu} \lVert{y_1 - \lambda}\rVert^2_2\\
						\text{s.t.} \quad
							& \xi - y^\top B^{-1} y \geq \delta
					\end{split}
				\end{equation}

			\begin{theo}
				问题(\ref{TrueRBRQ})的最优解为
				\begin{equation}
					\begin{split}\label{TrueRBRA}
						y_1 = & (2 \mu I + X_{\alpha, \alpha})^{-1} X_{\alpha, \alpha}\tilde{b}\\
						y_2 = & \frac{1}{2 \mu} X_{\beta, \alpha} (\lambda - y_1)\\
						\xi = & \frac{1}{2 \mu} y_1^\top (\lambda - y_1) + \delta
					\end{split}
				\end{equation}
			\end{theo}

			\begin{proof}
				容易发现, 当 $\xi = y^\top B^{-1}y + \delta$ 时, 才可能取到最小值, 则(\ref{TrueRBRQ})等价于
				\begin{equation}
					\min_y y^\top B^{-1}y + \frac{1}{2\mu} \lVert{y_1-\lambda}\rVert^2_2
				\end{equation}
				令其梯度为0
				\begin{equation}\label{GradTrueRBR}
						{\begin{pmatrix}
							X_{\alpha, \alpha} & X_{\alpha, \beta}\\
							X_{\beta, \alpha} & X_{\beta, \beta}
						\end{pmatrix}}^{-1}
						\begin{pmatrix}
							y_1 \\ y_2
						\end{pmatrix}
					+	\frac{1}{2\mu}
						\begin{pmatrix}
							y_1 - \lambda \\ 0
						\end{pmatrix}
					=	0
				\end{equation}
				变形可得 
				\begin{equation}
						\begin{pmatrix}
							y_1 \\ y_2
						\end{pmatrix}
					+	\frac{1}{2\mu}
						\begin{pmatrix}
							X_{\alpha, \alpha} \\ X_{\beta, \alpha}
						\end{pmatrix}
						(y_1 - \lambda)
					=	0
				\end{equation}
				则 
				\begin{equation}
					\begin{split}\label{TrueRBRAY}
						y_1 =
							& (2 \mu I + X_{\alpha, \alpha})^{-1} X_{\alpha, \alpha}\\
						y_2 =
							& \frac{1}{2\mu} X_{\beta, \alpha} (y_1 - \lambda)
					\end{split}
				\end{equation}
				那么由(\ref{GradTrueRBR})和(\ref{TrueRBRAY}), 有
				\begin{equation}\label{TrueRBRAXi}
						\xi
					=	y^\top B^{-1}y + \delta
					= 	- \frac{1}{2\mu}
						\begin{pmatrix}
							y_1 \\ y_2
						\end{pmatrix}^\top
						\begin{pmatrix}
							y_1 - \lambda \\ 0
						\end{pmatrix}
						+ \delta
					=	\frac{1}{2 \mu} y_1^\top (\lambda - y_1) + \delta
				\end{equation}
				即 (\ref{TrueRBRQ})的最优解为(\ref{TrueRBRA})
			\end{proof}
			
			\paragraph{}
				\quad 我们可以让 $i$ 循环取遍 $\{1, \cdots, n\}$ , 逐行求解(\ref{TrueRBRQ}), 最终解决问题(\ref{q4}). 给出算法
				\begin{algo}
					\quad\\
					步1 \quad 给出 $\delta \ge 0$ , $X^1 \succ 0$ , $F^0 = tr(X^1)$ , $F^1 = + \infty$ , $\epsilon > 0$ , 设置计数器 $k = 1$ , $i = 1$ ;\\
					步2 \quad 若 $\frac{\lvert{F^{k - 1}-F^k}\rvert}{\max\{1,\lvert{F^{k - 1}}\rvert\}}\leq\epsilon$ , 则停止;\\
					步3 \quad 若 $i>n$ , 则令 $i=1$ , $X^{k + 1}=X^k$ , $k=k + 1$ , $F^k = tr(X^k)$ , 转步2;\\
					步4 \quad 求出 $i$ 对应的 $\alpha_i$ , $\beta_i$;\\
					步5 \quad 若 $\vert{\alpha_i}\vert$ = 0, 令 $X^k_{\alpha, \alpha} = x^l_{\alpha, \beta} = X^k_{\beta, \alpha} = 0$, $X^k_{\beta, \beta} = X^k$ , 否则按通常定义求出以上几个量.\\
					步6 \quad 按(\ref{TrueRBRA}), 计算当前最优解 $\xi$ , $y_1$ , $y_2$ , 以及 $y = [y_1, y_2]$;\\
					步7 \quad 令 $X^{k}_{i, i} = \xi$ , $X^{k}_{i, i^c} = y$ , $X^{k}_{i^c, i} = y^\top$;\\
					步8 \quad $i = i + 1$ , 转步3;
				\end{algo}


	\section{FPCA法}
		\subsection{FPC法}
			\paragraph{}
				\quad FPC法是一种基于不动点定理的算法, 可以解决问题(\ref{q5}). 

			\paragraph{}
				\quad $\lVert{X}\rVert_*+\frac{1}{2\mu}\lVert{\mathcal{A}(X)-b}\rVert_2^2$ 是一个凸函数, 求最优解只要求梯度为0的点. 但 $\lVert{X}\rVert_*$ 是不可微的, 故考虑次梯度, 即
				\begin{equation}\label{SubGrad}
					0 \in \mu \partial \lVert{X}\rVert_* + g(X)
				\end{equation}
				其中 $g(X) = \mathcal{A}^*(\mathcal{A}(X) - b)$
			
			\paragraph{}
				\quad 设 $Y = X - \psi g(X)$ , $\psi > 0$ 是给定常数, 则(\ref{SubGrad})等价于
				\begin{equation}\label{SubGrad2}
					0 \in \psi \mu \partial \lVert{X}\rVert_* + X - (X - \psi g(X)) = \psi \mu \partial \lVert{X}\rVert_* + X -Y
				\end{equation}

			\paragraph{}
				\quad (\ref{SubGrad2})恰好是 $\lVert{X}\rVert_* + \frac{1}{2} \Vert{X - Y}\Vert^2_F$ 的次梯度, 即(\ref{q4})等价于 
				\begin{equation}\label{FPCQ}
					\min \psi \mu \lVert{X}\rVert_* + \frac{1}{2} \Vert{X - Y}\Vert^2_F
				\end{equation}
			
			\paragraph{}
				\quad 引入矩阵的Shinkage算子, 定义如下

			\begin{define}[Shinkage算子]
				对 $X \in \mathbb{R}^{m \times n}$ 做奇异值分解, $X = U \text{Diag}(\sigma) V ^\top$ , $r = \text{rank}(X)$ , $U \in \mathbb{R}^{m \times r}$ , $V \in \mathbb{R}^{n \times r}$ , 对 $\forall \nu > 0$ , 定义向量 $\bar{\sigma} = (\bar{\sigma_1}, \cdots, \bar{\sigma_r})$ , 其中$\bar{\sigma_i} = \max \{\sigma_i - \nu, 0\}$ , 那么Shinkage算子定义为 $S_\nu(X) = U \text{Diag}(\bar{\sigma}) V ^\top$
			\end{define}

			\paragraph{}
				\quad 当认为(\ref{FPCQ})中的 $Y$ 是给定的情况下, 有如下定理
			\begin{theo}
				(\ref{FPCQ})的最优解为 $S_{\psi \mu}(Y)$, 其中 $S_{\psi \mu}(\cdot)$ 是Shinkage算子
			\end{theo}
			
			\begin{proof}
				\quad 不失一般性, 设 $m \le n$ , 记 $\nu = \psi \mu$ , $X = U \text{Diag}(\sigma) V ^\top$ , $Y = U_Y \text{Diag}(\gamma) V_Y ^\top$ 是 $X$ , $Y$ 的SVD, $\text{rank} X = r$ , $\text{rank} Y = t$.
			
				因为 $\partial \Vert{X}\Vert_* = \{UV^\top+W\vert U^\top W=0,WV=0,\lVert{W}\rVert_2\leq1\}$ , 找到矩阵 $\bar{U} \in \mathbb{R}^{m \times (m - r)}$ , $\bar{V} \in \mathbb{R}^{n \times (n - r)}$ , 使得 $\tilde{U} = [U, \bar{U}]$ , $\tilde{V} = [V, \bar{V}]$ 分别是 $m$ , $n$ 阶正交矩阵. 那么易验证, 当 $\bar{\sigma} \in \mathbb{R}^{m-r}_+$ , $\Vert{\sigma}\Vert_\infty \le 1$ , 形如 $W = \bar{U}[\text{Diag}(\bar{\sigma}), 0]\bar{V} ^\top$ 的矩阵 $W \in \partial \Vert{X}\Vert_*$ .

				若 $0 \in \nu \partial \lVert{X}\rVert_* + X -Y$ , 则说明 $\exists W \in \partial \lVert{X}\rVert_*$ 使 $\nu (UV ^\top + W) + X -Y = 0$ . 那么可以看到当 $W = \bar{U}[\text{Diag}(\bar{\sigma}), 0]\bar{V} ^\top$ , 则要求
				\begin{equation}
					\begin{split}\label{ShinkageCondition}
							&\nu (UV ^\top + W) + X -Y\\
						=	&(\nu U I V ^\top + \bar{U}[\text{Diag}(\bar{\sigma}), 0]\bar{V} ^\top + U \text{Diag}(\sigma) V ^\top) - Y\\
						=	&\begin{pmatrix}
								U \\ \bar{U}
							\end{pmatrix}
							\Bigg [
								\begin{pmatrix}
									\nu I & 0 & 0\\
									0 & 0 & 0
								\end{pmatrix}
								+
								\begin{pmatrix}
									0 & 0 & 0\\
									0 & \nu \text{Diag}(\bar{\sigma}) & 0
								\end{pmatrix}
								+
								\begin{pmatrix}
									\text{Diag}(\sigma) & 0 & 0\\
									0 & 0 & 0
								\end{pmatrix}
								\Bigg ]
							\begin{pmatrix}
								V \\ \bar{V}
							\end{pmatrix} ^\top 
							- U_Y \text{Diag}(\gamma) V_Y ^\top\\
						=	&\begin{pmatrix}
								U \\ \bar{U}
							\end{pmatrix}
							\begin{pmatrix}
								\nu I + \text{Diag}(\sigma) & 0 & 0\\
								0 & \nu \text{Diag}(\bar{\sigma}) & 0
							\end{pmatrix}
							\begin{pmatrix}
								V \\ \bar{V}
							\end{pmatrix} ^\top 
							- U_Y \text{Diag}(\gamma) V_Y ^\top = 0
					\end{split}
				\end{equation}

				当 $\gamma_1 \ge \cdots \ge \gamma_t \ge \nu$ , 那我们令 $X = S_\nu(Y)$ , 则 $r = t$ , $U = U_Y$ , $V = V_Y$ , $\sigma = (\gamma_1 - \nu, \cdots, \gamma_t - \nu)$ , 对于这样的 $X$ , 取 $\bar{\sigma} = 0$ 即 $W = 0$ , (\ref{ShinkageCondition})成立.

				当 $\gamma_1 \ge \cdots \ge \gamma_k \ge \nu \ge \gamma_{k + 1} \ge \cdots \ge \gamma_t$ , 那我们令 $X = S_\nu(Y)$ , 则 $r = k$ , $\sigma = (\gamma_1 - \nu, \cdots, \gamma_k - \nu, 0, \cdots, 0)$ , 对这样的 $X$ , 取 $\bar{\sigma} = (\gamma_{k + 1}/\nu, \cdots, \gamma_{t}/\nu, 0, \cdots, 0)$ , 同时令 $\bar{U}$ 的前 $t - k$ 行依次为 $U_Y$ 的 $k + 1$ 至 $t$ 行, $\bar{V}$ 的前 $t - k$ 行依次为 $V_Y$ 的 $k + 1$ 至 $t$ 行, 即 
					$
						\begin{pmatrix}
							U \\ \bar{U}
						\end{pmatrix} 
						=
						\begin{pmatrix}
							U_Y \\ \bar{U}'
						\end{pmatrix}
					$ ,
					$
						\begin{pmatrix}
							V \\ \bar{V}
						\end{pmatrix} 
						=
						\begin{pmatrix}
							V_Y \\ \bar{V}'
						\end{pmatrix}
					$ ,
				其中 $\bar{U}'$ 是 $\bar{U}$ 的后 $m - t$ 行, $\bar{V}'$ 是 $\bar{V}$ 的后 $n - t$ 行, 此时(\ref{ShinkageCondition})也成立.

				故 $S_{\psi \mu}(Y)$ 是(\ref{FPCQ})的解.
			\end{proof}
		\subsection{FPC法的收敛性}
			\paragraph{}
				\quad 也就是说, 我们只需要求出合适的 $Y$ , $S_{\psi \mu}(Y)$ 就是(\ref{q5})的解. 由 $X$ 与 $Y$ 的关系可以看出, 若 $X^*$ 是(\ref{q5})的解, 则
				\begin{equation}
						X^*
					=	S_{\psi \mu}(X^* - \mu g(X^*))
					=	S_{\psi \mu}(X^* - \mu \mathcal{A}^*(\mathcal{A}(X^*) - b))
				\end{equation}
				即 $X^*$ 是映射 $S_{\psi \mu} \circ h$ 的不动点, 其中 $h(X) = X - \mu g(X)$ .

			\paragraph{}
				\quad 我们有如下的结论
				\begin{theo}
					Shinkage算子 $S_\nu(\cdot)$ 是非扩张的, 即
					\begin{equation}
						\Vert{S_\nu(Y_1) - S_\nu(Y_2)}\Vert_F \le \Vert{Y_1 - Y_2}\Vert_F
					\end{equation}
				\end{theo}

				\begin{theo}
					当 $\mu \in (0, 2/\lambda_{max}(A ^\top A))$ , 其中 $A$ 满足 $\mathcal{A}(X) = A \text{vec}(X)$ , $h$ 是非扩张的, 即
					\begin{equation}
						\Vert{h(X_1) - h(X_2)}\Vert_F \le \Vert{X_1 - X_2}\Vert_F
					\end{equation}
				\end{theo}
				
			
			\paragraph{}
				\quad 那么很自然的推论是, 当 $\mu \in (0, 2/\lambda_{max}(A ^\top A))$
					\begin{equation}
						\Vert{S_{\psi \mu}(h(X_1)) - S_{\psi \mu}(h(X_2))}\Vert_F \le \Vert{h(X_1) - h(X_2)}\Vert_F \le \Vert{X_1 - X_2}\Vert_F
					\end{equation}
				即 $S_{\psi \mu} \circ h$ 是一个非扩张的映射, 由Brouwer不动点定理可知, 由任意 $X$ 开始进行迭代, 都能收敛到某个不动点.

		\subsection{奇异值计算的近似算法FPCA}
			\paragraph{}
				\quad 实际计算中, 上述迭代过程中, 每步都要求做奇异值分解, 这并不是一件容易的事. 我们认为问题(\ref{q5})中的原矩阵 $X$ 是一个低秩矩阵, 那么其奇异值大多都是 $0$ , 故可以考虑只求很少的几个奇异值.

			\paragraph{}
				\quad $A \in \mathbb{R}^{p \times q}$ , 取整数 $c$ , $d$ , $1 \le d \le c \le q$ , $(P_1, \cdots, P_q)$ , $P_i \ge 0$ , $\sum^{q}_{i = 1}P_i = 1$ . 构造随机向量 $(i_1, \cdots, i_c)$ , $P(i_t = j) = P_j$ , $t \in \{1, \cdots, c\}$ , $j \in \{1, \cdots, q\}$ . 再令随机矩阵
				\begin{equation}\label{FPCAC}
						C
					=	\begin{pmatrix}
							C^{(1)} \\ \cdots \\ C^{(c)}
						\end{pmatrix}
					=	\begin{pmatrix}
							A^{(i_i)}/\sqrt{c P_{i_1}} \\ \cdots \\ A^{(i_c)}/\sqrt{c P_{i_c}}
						\end{pmatrix}
					\in	\mathbb{R}^{p \times c}
				\end{equation}
				求 $C ^\top C$ 的特征值分解
				\begin{equation}\label{FPCASgm}
						C ^\top C 
					=	\sum^{c}_{i = 1}\sigma_i^2(C) y_i y_i^\top
				\end{equation}
				其中 $\sigma_i(C) \ge 0$ , 为 $C$ 的奇异值 , 再构造矩阵
				\begin{equation}\label{FPCAH}
						H 
					=	\begin{pmatrix}
							H^{(1)} \\ \cdots \\ H^{(d)}
						\end{pmatrix}
					=	\begin{pmatrix}
							Cy_1/\sigma_1(C) \\ \cdots \\ Cy_d/\sigma_d(C)
						\end{pmatrix}
					\in	\mathbb{R}^{p \times d}
				\end{equation}
				令
				\begin{equation}\label{FPCAAk}
						A_d
					=	H \text{Diag}(\sigma(C)) \big(A ^\top H \text{Diag}(1/\sigma(C))\big)^\top
				\end{equation}
				可以证明 $A_d$ 是 $A$ 的一个比较好的近似
				\begin{equation}
						\Vert{A - A_d}\Vert^2_\xi 
					\le	\min_{\text{rank}(D) \le d} \Vert{A - D}\Vert^2_\xi + ploylog(d, 1/c) \Vert{A}\Vert^2_\xi
				\end{equation}
				其中 $\xi = 2 \text{ 或 } F$ , $polylog$ 是多重对数函数. 
				
			\paragraph{}
				\quad 用这种近似的方法改进的FPC算法就是FPCA法, 给出算法
				\begin{algo}
					\quad\\
					步1 \quad 给出 $X^1$ , $\mu^0 > 0$ , $1 > \theta > 0$ , $\epsilon > 0$ , 设置计数器 $k = 1$;\\
					步2 \quad 若 $\mu^k = \mu^{k -1} \theta \le \epsilon$ , 则停止;\\
					步3 \quad 选取合适的 $\psi > 0$ ;\\
					步4 \quad 计算 $Y^k = X^k - \psi \mathcal{A}^*(\mathcal{A}(X^k) - b))$;\\
					步5 \quad 选取合适的 $d$ , $\{P_i\}$ , 按(\ref{FPCAC})至(\ref{FPCAAk}), 计算近似的奇异值分解 $Y_d = H \text{Diag}(\sigma(C)) \big(Y ^\top H \text{Diag}(1/\sigma(C))\big)^\top$\\
					步6 \quad 计算 $X^{k + 1} = S_{\psi \mu^k}(Y_d)$;\\
					步7 \quad $k = k + 1$, 转步2;
				\end{algo}
		


		
	\section{补充知识}
		此部分会给出一些阅读本文必备的结论,许多结论将略过证明.
		\subsection{奇异值分解}
			\paragraph{}
				\quad $\forall X \in \mathbb{R}^{p \times q}$ , $X = U D V^\top$ , 其中 $U \in \mathbb{R}^{p \times p}$ , $V \in \mathbb{R}^{q \times q}$ 是正交矩阵, $ D = \text{Diag}(\sigma) \in \mathbb{R}^{p \times q}$ 对角线上为非负实数,其他位置为0的矩阵.

			\paragraph{}
				\quad 这个分解称为\textbf{奇异值分解(SVD)}, 对角矩阵Diag($\sigma$)的每个对角元素 $\sigma_i$ 都是非负的, 称为矩阵的\textbf{奇异值}, 正交矩阵 $U$ 的列向量称为矩阵的\textbf{左奇异向量}, 正交矩阵 $V$ 的列向量称为矩阵的\textbf{右奇异向量}.

			\paragraph{}
				\quad 有时也认为 $X = U D V^\top$ , 其中 $U \in \mathbb{R}^{p \times r}$ , $V \in \mathbb{R}^{q \times r}$ 是列正交矩阵, $D \in \mathbb{R}^{r \times r}$ 是非负实对角矩阵,$r = rank(X)$.


		\subsection{罚函数}
			\paragraph{}
				\quad 对于约束优化问题:
				\begin{equation}
					\begin{split}\label{Q}
						\min_x \quad
							& f(x)\\
						\text{s.t.} \quad
							& c_i(x) = 0, \quad i = 1, \cdots, m_e;\\
							& c_i(x) \ge 0, \quad i = m_e + 1, \cdots, m
					\end{split}
				\end{equation}
			\paragraph{}
				\quad 我们可以通过把约束条件平方后, 乘上一个很大的常数 $\mu$ , 再加到目标函数上, 转化为\textbf{罚函数}:
				\begin{equation}
					P(x, \mu) = f(x) + \mu \lVert{\bar{c}(x)}\rVert^2_2
				\end{equation}
				其中
				$
						\bar{c}(x)
					=	(\bar{c}_1(x), \cdots, \bar{c}_m(x))
					\in	\mathbb{R}^{m}
				$ , \quad
				$\bar{c}_i(x)$如下定义:
				$
						\bar{c}_i(x)
					=	\begin{cases}
							c_i(x), \quad i \leq m_e\\
							\max \{0, c_i(x)\}, \quad i > m_e \\
						\end{cases}
				$ .
			\paragraph{}
				\quad 当 $\mu \rightarrow \infty$ , (\ref{Punish})和原问题(\ref{Q})等价.
				\begin{equation}\label{Punish}
					\min_x \quad P(x,\mu)
				\end{equation}

			\paragraph{}
				\quad 但在实际中, $\mu$ 无法取到无穷大, 为了克服这一缺点, 可以定义\textbf{增广Lagrange函数}(以下叙述仅考虑等值约束的情况, 即 $m_e = m$ ):
				\begin{equation}\label{ALag}
						P(x, \lambda, \mu)
					=	f(x) - \lambda^\top c(x) + \frac{1}{2} \mu \lVert{c(x)}\rVert^2_2
				\end{equation}
				其中 $\lambda$ , $\lambda$ , $\mu$, $c(x) \in \mathbb{R}^{m}$ 给定.

			\paragraph{}
				\quad (\ref{ALag})等价于以下的\textbf{Powell罚函数}:
				\begin{equation}\label{Pow}
						P(x, \theta, \mu)
					=	f(x) + \frac{1}{2} \mu \lVert{c(x) - \theta}\rVert^2_2
				\end{equation}
				其中 $c(x) , \theta \in \mathbb{R}^{m}$ .

			\paragraph{}
				\quad (\ref{Punish})与(\ref{Pow})只相差一个与 $x$ 无关的常数 $\frac{1}{2} \sigma \lVert{\theta}\rVert^2_2$ .

		\subsection{对偶问题}
			\paragraph{}
				\quad 对于约束优化问题(\ref{Q}),它的\textbf{Langrange函数}为:
				\begin{equation}
						L(x, \mu, \lambda)
					=	f(x) + \sum^{m_e}_{i = 1} \mu_i c_i(x) + \sum^{m}_{i = m_e + 1} \lambda_i c_i(x)
				\end{equation}

			\paragraph{}
				\quad 定义 $g(\mu, \lambda) = \inf_x L(x, \mu, \lambda)$, 通过这个函数我们可以把(\ref{Q})转化为它的对偶问题:
				\begin{equation}
					\begin{split}\label{Dual}
						\max_{\mu, \lambda} \quad
							& g(\mu,\lambda)\\
						\text{s.t.} \quad
							& \mu \succeq 0
					\end{split}
				\end{equation}
				当满足一定条件(KKT条件)时, (\ref{Dual})和(\ref{Q})是等价的.

		\subsection{次梯度}
			\paragraph{}
				\quad $f: E \rightarrow \mathbb{R}^{}$ 是一个定义在 $\mathbb{R}^{n}$ 的凸子集 $E$ 上的实值函数,则所有满足
				\begin{equation}
					f(y) - f(x) \geq u(y-x), \quad \forall y \in E
				\end{equation}
				的向量 $u$ 称为 $f$ 在 $x$ 点的\textbf{次梯度}, 所有这样的 $u$ 构成的集合称为 $f$ 在 $x$ 点的\textbf{次梯度集}.

			\paragraph{}
				\quad 次梯度集通常用 $\partial f(x)$ 表示
				\begin{equation}
						\partial f(x)
					=	\{u \in \mathbb{R}^{m} \vert f(y) - f(x) \geq u(y - x), \quad \forall y \in E\}
				\end{equation}
				当函数在 $x$ 点可微, $\partial f(x) = \{f^\prime(x)\}$ ; 当函数在 $x$ 点不可微, $\partial f(x)$ 是一个非空的紧凸集.

			\paragraph{}
				\quad 对于不可微函数或者不可微点, 我们可以采用次梯度替代梯度进行分析. 众所周知, 一个点是最优解的必要条件是该点梯度为0. 相应的,有如下结论:
			\begin{theo}
				$x^*$ 是(\ref{Q})问题的最优解的一个必要条件是: $0 \in \partial f(x^*)$ . 特别的, 若 $f$ 是凸函数, 则是充要条件.
			\end{theo}

		\subsection{矩阵范数}
			\paragraph{}
				\quad 以下默认 $A \in \mathbb{R}^{m \times n}$ , $x \in \mathbb{R}^{n}$ , $k = \max \{m, n\}$ , $\lambda(A) = (\lambda_1(A), \cdots, \lambda_k(A)) \in \mathbb{R}^{k}$ 是矩阵 $A$ 的奇异值向量, $\lambda_i(A)$ 是矩阵 $A$ 的第i个奇异值.
			\subsubsection{诱导-p范数}
				\paragraph{}
					\quad 矩阵的\textbf{诱导-p范数}是将矩阵看作线性算子, 由向量的p-范数诱导而来.
					\[
						\lVert{A}\rVert_p = \sup_{\lVert{x}\rVert_p \leq 1}\lVert{Ax}\rVert_p
					\]

				\paragraph{}
					\quad 常见的有\textbf{2-范数}:
					\[
						\lVert{A}\rVert_2 = \max_i \lambda_i(A)
					\]

				\paragraph{}
					\quad \textbf{1-范数}, 又称\textbf{列范数}:
					\[
						\lVert{A}\rVert_1 = \max_{1 \leq j \leq n}\sum_{i = 1}^m \lvert{a_{ij}}\rvert
					\]

				\paragraph{}
					\quad \textbf{$\infty$-范数}, 又称\textbf{行范数}:
					\[
						\lVert{A}\rVert_\infty = \max_{1 \leq i \leq m}\sum_{j = 1}^n \lvert{a_{ij}}\rvert
					\]

			\subsubsection{F-范数}
				\paragraph{}
					\quad 矩阵的\textbf{F-范数}定义类似于向量的2-范数:
					\[
						\lVert{A}\rVert_F = (\sum_{i, j} a_{ij}^2)^{\frac{1}{2}}
					\]
				\paragraph{}
					\quad 定义矩阵内积 $\langle{A, X}\rangle = tr(A^\top X)$, F-范数与矩阵内积是相容的, 可以看作内积诱导的范数, 即 $\lVert{A}\rVert_F = \langle{A, A}\rangle^{\frac{1}{2}}$ .

			\subsubsection{Schaten-p范数}
				\paragraph{}
					\quad 矩阵的\textbf{Schaten-p范数}是p-范数应用与矩阵奇异值向量所得的:
					\[
							\lVert{A}\rVert_p
						=	(\sum_i^k \lambda_i(A)^p)^{\frac{1}{p}}
						=	\lVert{\lambda(A)}\rVert_p
					\]
			
			\subsubsection{核范数}
				\paragraph{}
					\quad 矩阵的\textbf{核范数}, 又称\textbf{迹范数}, 是在 $p = 1$ 时的Schaten-p范数:
					\[
							\lVert{A}\rVert_*
						=	\sum_i^k \lambda_i(X)
						=	tr(\sqrt{A A^\top})
						=	\lVert{A}\rVert_{tr}
					\]

				\paragraph{}
					\quad 特别的, 当 $A$ 是对称正定的方阵, 则有 $ A = \sqrt{A A^\top}$ , 即
					\[
						\lVert{A}\rVert_* = tr(A)
					\]

				\paragraph{}
					\quad 核范数 $\lVert{A}\rVert_* = \lVert{\lambda(A)}\rVert_1$ , 而矩阵的秩 $rank(A) = \lVert{\lambda(A)}\rVert_0$ , 由此可以看出, 核范数与秩的关系就是1-范数与0-范数的关系, 故采用核范数来近似秩.

				\paragraph{}
					\quad 核范数是非光滑函数的, 次梯度集如下
					\begin{equation}\label{NuNormSubGrad}
							\partial \lVert{X}\rVert_*
						=	\{U V^\top + W \vert U^\top W = 0,WV = 0, \lVert{W}\rVert_2 \leq 1\}
					\end{equation}
					其中 $X = U D V^\top$
\end{document}
